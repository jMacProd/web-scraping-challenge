{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#enables to read and search html\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "#allows Python to reach out to the internet \n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 88.0.4324\n",
      "[WDM] - Get LATEST driver version for 88.0.4324\n",
      "[WDM] - Driver [/Users/J/.wdm/drivers/chromedriver/mac64/88.0.4324.96/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "#splinter actications\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tell the splinter browser to go to this website\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser' - using the splinter browser\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())\n",
    "#now the full html has appeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect the latest News Title and Paragraph Text\n",
    "    # Examine the results, then determine element that contains sought info\n",
    "    # results are returned as an iterable list\n",
    "results = soup.find_all('li', class_='slide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the text to variables that you can reference later\n",
    "\n",
    "news_title = []\n",
    "paragraph_text = []\n",
    "\n",
    "# Loop through returned results\n",
    "for result in results:\n",
    "    \n",
    "    # Retrieve the news item title\n",
    "    title = result.find('div', class_='content_title')\n",
    "    \n",
    "    # Access the titles text content\n",
    "    title_text = title.a.text\n",
    "    \n",
    "    # Retrieve the Paragraph Text\n",
    "    article_teaser = result.find('div', class_='article_teaser_body')\n",
    "    \n",
    "    # Access the paragraphs's text content\n",
    "    article_teaser_text = article_teaser.text\n",
    "    \n",
    "    #Append the lists\n",
    "    news_title.append(title_text)\n",
    "    paragraph_text.append(article_teaser_text)\n",
    "    \n",
    "    \n",
    "    #print(\"\")\n",
    "    #print(title_text)\n",
    "    #print(\"--\")\n",
    "    #print(article_teaser_text)\n",
    "    #print(\"--------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Close the browser after scraping\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set new browser\n",
    "browserfi = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "#Tell the splinter browser to go to this website\n",
    "\n",
    "urlfi = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/'\n",
    "browserfi.visit(urlfi + 'index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser' - using the splinter browser\n",
    "htmlfi = browserfi.html\n",
    "soupfi = bs(htmlfi, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soupfi.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect the image container\n",
    "\n",
    "resultsfi = soupfi.find('div', class_='floating_text_area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultsfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "link = resultsfi.a['href']\n",
    "featured_image_url = urlfi + link\n",
    "\n",
    "#featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "browserfi.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit the Mars Facts webpage [here](https://space-facts.com/mars/)\n",
    "urlmf = 'https://space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "    # Use Panda's `read_html` to parse the url\n",
    "\n",
    "tables = pd.read_html(urlmf)\n",
    "#tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_fact = tables[0]\n",
    "#mars_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index\n",
    "mars_fact.set_index(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mars_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove index label\n",
    "mars_fact.index.names = ['']\n",
    "#mars_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset columns\n",
    "mars_fact.columns = ['Mars']\n",
    "#mars_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Pandas to convert the data to a HTML table string.\n",
    "mars_fact_html = mars_fact.to_html()\n",
    "#mars_fact_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may have to strip unwanted newlines to clean up the table.\n",
    "mars_fact_html = mars_fact_html.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mars_fact_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also save the table directly to a file.\n",
    "    #sample - df.to_html('table.html')\n",
    "mars_fact.to_html('mars_fact.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres\n",
    "Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "sleep(1)\n",
    "\n",
    "#set new browser\n",
    "browsermh = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "#Tell the splinter browser to go to this website\n",
    "\n",
    "urlmh = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browsermh.visit(urlmh)     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define main url\n",
    "main_page = \"https://astrogeology.usgs.gov\"\n",
    "#print(main_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list called hemisphere_image_urls\n",
    "\n",
    "hemheader = []\n",
    "hemisphere_image_urls = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through returned results\n",
    "for x in range(0, 4):\n",
    "    \n",
    "    sleep(1)\n",
    "    \n",
    "    # Create BeautifulSoup object; parse with 'html.parser' - using the splinter browser\n",
    "    htmlmh = browsermh.html\n",
    "    \n",
    "    #Parse it to Beautiful Soup - makes the html searchable by tags\n",
    "    soupmh = bs(htmlmh, 'html.parser')\n",
    "    \n",
    "    \n",
    "    #Find the link container\n",
    "    resultsmh = soupmh.find_all('div', class_='description')\n",
    "    #print(resultsmh[x])\n",
    "    \n",
    "    \n",
    "    #Retrieve the link container\n",
    "    linkcontmh = resultsmh[x].a['href']\n",
    "    #print(linkcontmh)\n",
    "    \n",
    "    #Retrieve header\n",
    "    header = resultsmh[x].a.text\n",
    "    #print(header)\n",
    "    #print(\"--\")\n",
    "    \n",
    "    \n",
    "    #clicks on x link to go to next page\n",
    "    browsermh.visit(main_page+linkcontmh)\n",
    "    \n",
    "    sleep(1)\n",
    "    #print(browsermh.url)\n",
    "    \n",
    "    htmlnp = browsermh.html\n",
    "    soupnp = bs(htmlnp, 'html.parser')\n",
    "    \n",
    "    #Collect np link container\n",
    "    resultsnp = soupnp.find('div', class_='wide-image-wrapper')\n",
    "    #print(resultsnp)\n",
    "    \n",
    "    \n",
    "    find_images = resultsnp.find_all('img')[1]\n",
    "    \n",
    "    \n",
    "    #Find second li tag\n",
    "    litag = find_images['src']\n",
    "    \n",
    "\n",
    "    \n",
    "          \n",
    "    imgnp_url = main_page+litag\n",
    "    #print(imgnp_url)\n",
    "          \n",
    "    #print(\"--------\")\n",
    "          \n",
    " \n",
    "   \n",
    "    #Append the lists\n",
    "    hemheader.append(header)\n",
    "    hemisphere_image_urls.append(imgnp_url)\n",
    "    \n",
    "       \n",
    "        \n",
    "    #hemisphere_image_urls.append(link_dict)\n",
    "    \n",
    "    \n",
    "    #Go back to main page\n",
    "    browsermh.back()\n",
    "\n",
    "browsermh.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check lists\n",
    "#hemheader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
